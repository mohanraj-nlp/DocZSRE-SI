{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47f7b00a-b1f7-400e-a461-856dcdf5a77e",
   "metadata": {},
   "source": [
    "# Similarity based Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ed3bfd5-eb91-4c2e-8cf4-1bb117e5bdd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import evaluation as eval\n",
    "from collections import Counter\n",
    "from typing import List, Tuple, Union\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from entity_pair_refinement import EntityPairRefinement\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, auc, roc_curve, roc_auc_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "346d42cc-00c3-4028-be98-d1210e575810",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ef7edb6-01a9-49a6-a213-377605f732fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./RE-DocRED_Results/only_descriptions_and_hypernyms.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a29bf55-4f5e-471c-81b5-66ba227eb575",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_relation_labels = ['manufacturer', 'director', 'place of birth', 'member of', 'influenced by']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45793e43-b0ca-4f36-861f-341d6c05dff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4049"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5467a74e-5617-4c14-a5f1-adb1e70b1128",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'tokenized_sent': [['The',\n",
       "   'short',\n",
       "   '-',\n",
       "   'beaked',\n",
       "   'common',\n",
       "   'dolphin',\n",
       "   '(',\n",
       "   'Delphinus',\n",
       "   'delphis',\n",
       "   ')',\n",
       "   'is',\n",
       "   'a',\n",
       "   'species',\n",
       "   'of',\n",
       "   'common',\n",
       "   'dolphin',\n",
       "   '.'],\n",
       "  ['It',\n",
       "   'has',\n",
       "   'a',\n",
       "   'larger',\n",
       "   'range',\n",
       "   'than',\n",
       "   'the',\n",
       "   'long',\n",
       "   '-',\n",
       "   'beaked',\n",
       "   'common',\n",
       "   'dolphin',\n",
       "   '(',\n",
       "   'D.',\n",
       "   'capensis',\n",
       "   ')',\n",
       "   ',',\n",
       "   'occurring',\n",
       "   'throughout',\n",
       "   'warm',\n",
       "   '-',\n",
       "   'temperate',\n",
       "   'and',\n",
       "   'tropical',\n",
       "   'oceans',\n",
       "   ',',\n",
       "   'including',\n",
       "   'the',\n",
       "   'Indian',\n",
       "   'Ocean',\n",
       "   'although',\n",
       "   'in',\n",
       "   'smaller',\n",
       "   'quantities',\n",
       "   'than',\n",
       "   'other',\n",
       "   'places',\n",
       "   'they',\n",
       "   'are',\n",
       "   'found',\n",
       "   '.'],\n",
       "  ['There',\n",
       "   'are',\n",
       "   'more',\n",
       "   'short',\n",
       "   '-',\n",
       "   'beaked',\n",
       "   'common',\n",
       "   'dolphins',\n",
       "   'than',\n",
       "   'any',\n",
       "   'other',\n",
       "   'dolphin',\n",
       "   'species',\n",
       "   'in',\n",
       "   'the',\n",
       "   'warm',\n",
       "   '-',\n",
       "   'temperate',\n",
       "   'portions',\n",
       "   'of',\n",
       "   'the',\n",
       "   'Atlantic',\n",
       "   'and',\n",
       "   'Pacific',\n",
       "   'Oceans',\n",
       "   '.'],\n",
       "  ['It',\n",
       "   'is',\n",
       "   'also',\n",
       "   'found',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Caribbean',\n",
       "   'and',\n",
       "   'Mediterranean',\n",
       "   'Seas',\n",
       "   '.'],\n",
       "  ['The',\n",
       "   'short',\n",
       "   '-',\n",
       "   'beaked',\n",
       "   'common',\n",
       "   'dolphin',\n",
       "   'is',\n",
       "   'also',\n",
       "   'abundant',\n",
       "   'in',\n",
       "   'the',\n",
       "   'Black',\n",
       "   'Sea',\n",
       "   ',',\n",
       "   'Gulf',\n",
       "   'of',\n",
       "   'Mexico',\n",
       "   ',',\n",
       "   'and',\n",
       "   'Red',\n",
       "   'Sea',\n",
       "   '.'],\n",
       "  ['They',\n",
       "   'follow',\n",
       "   'the',\n",
       "   'gulf',\n",
       "   'stream',\n",
       "   'up',\n",
       "   'to',\n",
       "   'Norwegian',\n",
       "   'waters',\n",
       "   '.'],\n",
       "  ['Seldom',\n",
       "   'do',\n",
       "   'any',\n",
       "   'short',\n",
       "   '-',\n",
       "   'beaked',\n",
       "   'dolphin',\n",
       "   'venture',\n",
       "   'near',\n",
       "   'the',\n",
       "   'Arctic',\n",
       "   '.']],\n",
       " 'entities': [{'id': 2,\n",
       "   'group': 0,\n",
       "   'label': 'MISC',\n",
       "   'position': {'start_offset_token': 7, 'end_offset_token': 9},\n",
       "   'mention': 'Delphinus delphis'},\n",
       "  {'id': 3,\n",
       "   'group': 1,\n",
       "   'label': 'MISC',\n",
       "   'position': {'start_offset_token': 13, 'end_offset_token': 15},\n",
       "   'mention': 'D. capensis'},\n",
       "  {'id': 4,\n",
       "   'group': 2,\n",
       "   'label': 'LOC',\n",
       "   'position': {'start_offset_token': 28, 'end_offset_token': 30},\n",
       "   'mention': 'Indian Ocean'},\n",
       "  {'id': 5,\n",
       "   'group': 3,\n",
       "   'label': 'LOC',\n",
       "   'position': {'start_offset_token': 21, 'end_offset_token': 22},\n",
       "   'mention': 'Atlantic'},\n",
       "  {'id': 6,\n",
       "   'group': 4,\n",
       "   'label': 'LOC',\n",
       "   'position': {'start_offset_token': 23, 'end_offset_token': 25},\n",
       "   'mention': 'Pacific Oceans'},\n",
       "  {'id': 7,\n",
       "   'group': 5,\n",
       "   'label': 'LOC',\n",
       "   'position': {'start_offset_token': 6, 'end_offset_token': 7},\n",
       "   'mention': 'Caribbean'},\n",
       "  {'id': 8,\n",
       "   'group': 6,\n",
       "   'label': 'LOC',\n",
       "   'position': {'start_offset_token': 8, 'end_offset_token': 10},\n",
       "   'mention': 'Mediterranean Seas'},\n",
       "  {'id': 9,\n",
       "   'group': 7,\n",
       "   'label': 'LOC',\n",
       "   'position': {'start_offset_token': 11, 'end_offset_token': 13},\n",
       "   'mention': 'Black Sea'},\n",
       "  {'id': 10,\n",
       "   'group': 8,\n",
       "   'label': 'LOC',\n",
       "   'position': {'start_offset_token': 14, 'end_offset_token': 17},\n",
       "   'mention': 'Gulf of Mexico'},\n",
       "  {'id': 11,\n",
       "   'group': 9,\n",
       "   'label': 'LOC',\n",
       "   'position': {'start_offset_token': 19, 'end_offset_token': 21},\n",
       "   'mention': 'Red Sea'},\n",
       "  {'id': 12,\n",
       "   'group': 10,\n",
       "   'label': 'LOC',\n",
       "   'position': {'start_offset_token': 7, 'end_offset_token': 8},\n",
       "   'mention': 'Norwegian'},\n",
       "  {'id': 13,\n",
       "   'group': 11,\n",
       "   'label': 'LOC',\n",
       "   'position': {'start_offset_token': 10, 'end_offset_token': 11},\n",
       "   'mention': 'Arctic'}],\n",
       " 'relation': [],\n",
       " 'relation_triplet': [],\n",
       " 'unique_entity_side_information': [{'entity_mention': 'Delphinus delphis',\n",
       "   'entity_type': 'MISC',\n",
       "   'description': 'Delphinus delphis, commonly known as the short-beaked common dolphin, is a widely distributed species found in warm-temperate and tropical oceans, notably abundant in the Atlantic and Pacific Oceans, as well as in the Caribbean, Mediterranean, and Black Seas.',\n",
       "   'hypernym_llm': 'marine mammal'},\n",
       "  {'entity_mention': 'D. capensis',\n",
       "   'entity_type': 'MISC',\n",
       "   'description': 'D. capensis, commonly known as the long-beaked common dolphin, is a species that has a more restricted range compared to the short-beaked common dolphin and is predominantly found in warm-temperate and tropical oceans.',\n",
       "   'hypernym_llm': 'marine mammal'},\n",
       "  {'entity_mention': 'Indian Ocean',\n",
       "   'entity_type': 'LOC',\n",
       "   'description': 'The Indian Ocean is a warm, tropical oceanic region where the short-beaked common dolphin is found, albeit in smaller quantities compared to other locations.',\n",
       "   'hypernym_llm': 'ocean'},\n",
       "  {'entity_mention': 'Atlantic',\n",
       "   'entity_type': 'LOC',\n",
       "   'description': 'The Atlantic is a significant oceanic region where the short-beaked common dolphin thrives, being more populous in its warm-temperate portions compared to other dolphin species.',\n",
       "   'hypernym_llm': 'ocean'},\n",
       "  {'entity_mention': 'Pacific Oceans',\n",
       "   'entity_type': 'LOC',\n",
       "   'description': 'The Pacific Oceans are significant habitats for the short-beaked common dolphin, a species that thrives in warm-temperate and tropical waters, making it one of the most abundant dolphin species in these regions.',\n",
       "   'hypernym_llm': 'ocean'},\n",
       "  {'entity_mention': 'Caribbean',\n",
       "   'entity_type': 'LOC',\n",
       "   'description': 'The Caribbean is a region that serves as a habitat for the short-beaked common dolphin, contributing to its distribution in warm-temperate and tropical waters.',\n",
       "   'hypernym_llm': 'geographical region'},\n",
       "  {'entity_mention': 'Mediterranean Seas',\n",
       "   'entity_type': 'LOC',\n",
       "   'description': 'The Mediterranean Seas are a significant habitat for the short-beaked common dolphin, a species that thrives in warm-temperate and tropical regions of the ocean.',\n",
       "   'hypernym_llm': 'marine ecosystem'},\n",
       "  {'entity_mention': 'Black Sea',\n",
       "   'entity_type': 'LOC',\n",
       "   'description': 'The Black Sea is a significant marine habitat where the short-beaked common dolphin (Delphinus delphis) is abundant, contributing to the biodiversity of this warm-temperate region.',\n",
       "   'hypernym_llm': 'marine body of water'},\n",
       "  {'entity_mention': 'Gulf of Mexico',\n",
       "   'entity_type': 'LOC',\n",
       "   'description': 'The Gulf of Mexico is a significant marine habitat known for its biodiversity, including the abundant presence of the short-beaked common dolphin, a species prevalent in warm-temperate and tropical oceans.',\n",
       "   'hypernym_llm': 'marine region'},\n",
       "  {'entity_mention': 'Red Sea',\n",
       "   'entity_type': 'LOC',\n",
       "   'description': 'The Red Sea is a warm sea located between northeastern Africa and the Arabian Peninsula, known for its biodiversity and as a habitat for various marine species, including the short-beaked common dolphin.',\n",
       "   'hypernym_llm': 'body of water'},\n",
       "  {'entity_mention': 'Norwegian',\n",
       "   'entity_type': 'LOC',\n",
       "   'description': 'Norwegian waters are part of the habitat range for the short-beaked common dolphin, which is primarily found in warm-temperate and tropical oceans.',\n",
       "   'hypernym_llm': 'geographical feature'},\n",
       "  {'entity_mention': 'Arctic',\n",
       "   'entity_type': 'LOC',\n",
       "   'description': 'The Arctic is a polar region located at the northernmost part of Earth, characterized by its cold climate, ice-covered waters, and limited presence of marine species like the short-beaked common dolphin.',\n",
       "   'hypernym_llm': 'polar region'}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2bf67e2-c517-4669-9f8f-6fbfc1860bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['manufacturer', 'director', 'place of birth', 'member of', 'influenced by']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_relation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb1417d3-a97d-43f5-ad92-f2566f0cbea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entity_sentence(entity, tokenized_document):\n",
    "    # Convert entity to lowercase for case-insensitive search\n",
    "    entity_lower = entity.lower()\n",
    "\n",
    "    # Loop through the sentences to check for the entity\n",
    "    for idx, sentence in enumerate(tokenized_document):\n",
    "        if any(entity_lower in word.lower() for word in sentence):  # Check if entity exists in sentence\n",
    "            return idx + 1  # Return the sentence number and break the loop\n",
    "\n",
    "    return 0  # Return None if entity is not found in any sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04cf7ba4-5674-46cd-8cd8-ea1eae9cd054",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_test = []\n",
    "rel_count = 0\n",
    "for item in data:\n",
    "    if item['relation_triplet']:\n",
    "        for rel in item['relation_triplet']:\n",
    "            rel_count=rel_count+1\n",
    "            if rel[\"relation\"].lower() in unseen_relation_labels and rel['relation'].lower()!=\"no_relation\":\n",
    "                try:\n",
    "                    head_mention = rel[\"head\"]\n",
    "                    tail_mention = rel[\"tail\"]\n",
    "                    head_side_information = [ent_s for ent_s in item['unique_entity_side_information'] if ent_s['entity_mention'].lower()==head_mention.lower()][0]\n",
    "                    tail_side_information = [ent_s for ent_s in item['unique_entity_side_information'] if ent_s['entity_mention'].lower()==tail_mention.lower()][0]\n",
    "                    loc_head_mention = find_entity_sentence(head_mention, item['tokenized_sent'])\n",
    "                    loc_tail_mention = find_entity_sentence(tail_mention, item['tokenized_sent'])\n",
    "                    data_to_test.append(\n",
    "                        {\n",
    "                            \"head_side_information\": head_side_information,\n",
    "                            \"tail_side_information\": tail_side_information,\n",
    "                            \"relation\": rel[\"relation\"],\n",
    "                            \"in_which_sentence_and_total_sentence\": [loc_head_mention, loc_tail_mention, len(item['tokenized_sent'])]\n",
    "                        }\n",
    "                    )\n",
    "                except:\n",
    "                    print(f\"Issue in ID: {item['id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53624730-186e-4629-92a2-a48dbcfdd182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72819\n"
     ]
    }
   ],
   "source": [
    "print(rel_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ff80a80-5e64-4a2a-a89c-9d63591f34c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2320\n"
     ]
    }
   ],
   "source": [
    "print(len(data_to_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17b9c777-a09b-4071-824d-62f7faa32a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48c702ca-5dd0-44d9-9b83-9539f423b3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze()\n",
    "    return embeddings\n",
    "\n",
    "def cosine_similarity(embedding_a, embedding_b):\n",
    "    return np.dot(embedding_a, embedding_b) / (np.linalg.norm(embedding_a) * np.linalg.norm(embedding_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe5358d9-6c4c-4dbc-9eed-8ba760fb85f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confidence(similarities):\n",
    "    \"\"\"\n",
    "    Calculate confidence score based on consistency of different similarity measures\n",
    "    \"\"\"\n",
    "    similarities = np.array(similarities)\n",
    "    \n",
    "    # Calculate mean and standard deviation\n",
    "    mean_sim = np.mean(similarities)\n",
    "    std_sim = np.std(similarities)\n",
    "    \n",
    "    # Higher confidence if similarities are consistent (low std dev) and high mean\n",
    "    consistency = 1 / (1 + std_sim)  # Inverse of standard deviation\n",
    "    confidence = (mean_sim + consistency) / 2\n",
    "    \n",
    "    return confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "013d60af-a3ad-4dbd-88bc-c33904cb3282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_unseen_relation(head, tail, model, tokenizer, unseen_labels):\n",
    "    \"\"\"\n",
    "    Enhanced unseen relation prediction with dynamic weighting and semantic role analysis\n",
    "    \"\"\"\n",
    "\n",
    "    combined_description = head['description'] + \"<SEP>\" + tail['description']\n",
    "    head_hypernym = head['hypernym_llm']\n",
    "    tail_hypernym = tail['hypernym_llm']\n",
    "    head_type = head['entity_type']\n",
    "    tail_type = tail['entity_type']\n",
    "    \n",
    "    unseen_scores = []\n",
    "    \n",
    "    # Generate base embeddings\n",
    "    description_embedding = generate_embedding(combined_description, model, tokenizer)\n",
    "    head_hypernym_embedding = generate_embedding(head_hypernym, model, tokenizer)\n",
    "    tail_hypernym_embedding = generate_embedding(tail_hypernym, model, tokenizer)\n",
    "    head_type_embedding = generate_embedding(head_type, model, tokenizer)\n",
    "    tail_type_embedding = generate_embedding(tail_type, model, tokenizer)\n",
    "    \n",
    "    # Generate semantic role embeddings for head and tail\n",
    "    head_role = f\"{head_type} acting as a subject, described as {head_hypernym}\"\n",
    "    tail_role = f\"{tail_type} acting as a subject, described as {tail_hypernym}\"\n",
    "    head_role_embedding = generate_embedding(head_role, model, tokenizer)\n",
    "    tail_role_embedding = generate_embedding(tail_role, model, tokenizer)\n",
    "    \n",
    "    # Create context vector from description\n",
    "    context_embedding = generate_embedding(f\"Relation between {head_type} and {tail_type}\", model, tokenizer)\n",
    "    \n",
    "    # Compare with each unseen relation label\n",
    "    for label in unseen_labels:\n",
    "        # Generate embeddings for label and its variations\n",
    "        label_embedding = generate_embedding(label, model, tokenizer)\n",
    "        label_context = generate_embedding(f\"relation {label} between {head_type} and {tail_type}\", model, tokenizer)\n",
    "        \n",
    "        # Calculate base similarities\n",
    "        description_similarity = cosine_similarity(label_embedding.numpy(), description_embedding.numpy())\n",
    "        head_hypernym_similarity = cosine_similarity(label_embedding.numpy(), head_hypernym_embedding.numpy())\n",
    "        tail_hypernym_similarity = cosine_similarity(label_embedding.numpy(), tail_hypernym_embedding.numpy())\n",
    "        head_type_similarity = cosine_similarity(label_embedding.numpy(), head_type_embedding.numpy())\n",
    "        tail_type_similarity = cosine_similarity(label_embedding.numpy(), tail_type_embedding.numpy())\n",
    "        \n",
    "        # Calculate semantic role similarities\n",
    "        head_role_similarity = cosine_similarity(label_context.numpy(), head_role_embedding.numpy())\n",
    "        tail_role_similarity = cosine_similarity(label_context.numpy(), tail_role_embedding.numpy())\n",
    "        \n",
    "        # Calculate context similarity\n",
    "        context_similarity = cosine_similarity(label_embedding.numpy(), context_embedding.numpy())\n",
    "        \n",
    "        # Dynamic weight calculation based on context similarity\n",
    "        context_weight = (1 + context_similarity) / 2  # Normalize to 0.5-1.0 range\n",
    "        \n",
    "        # Calculate semantic compatibility\n",
    "        semantic_score = (head_role_similarity + tail_role_similarity) / 2  #Because both Head Role and Tail Role Contribute (On telling which Sub or Obj)\n",
    "        \n",
    "        # Calculate confidence based on consistency\n",
    "        confidence = calculate_confidence([\n",
    "            description_similarity,\n",
    "            head_hypernym_similarity,\n",
    "            tail_hypernym_similarity,\n",
    "            head_type_similarity,\n",
    "            tail_type_similarity,\n",
    "            head_role_similarity,\n",
    "            tail_role_similarity\n",
    "        ])\n",
    "        \n",
    "        # Final weighted score with dynamic weighting\n",
    "        total_score = (\n",
    "            (0.4 * description_similarity) +\n",
    "            (0.1 * head_hypernym_similarity) +\n",
    "            (0.1 * tail_hypernym_similarity) +\n",
    "            (0.1 * head_type_similarity) +\n",
    "            (0.1 * tail_type_similarity) +\n",
    "            (0.1 * semantic_score) +\n",
    "            (0.1 * context_similarity)\n",
    "        ) * confidence\n",
    "        \n",
    "        unseen_scores.append((label, total_score))\n",
    "    \n",
    "    # Sort by total score and return top predictions with confidence\n",
    "    sorted_predictions = sorted(unseen_scores, key=lambda x: x[1], reverse=True)\n",
    "    return sorted_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defb5180-5e69-4370-896a-2f833bf7e32c",
   "metadata": {},
   "source": [
    "### Run Data to Identify Unseen Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "439da52b-0f8f-45a5-93cf-96f5d1fec278",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2320\n",
      "Matching: 22\n",
      "Matching: 23\n",
      "Matching: 40\n",
      "Matching: 53\n",
      "Matching: 54\n",
      "Matching: 59\n",
      "Matching: 60\n",
      "Matching: 70\n",
      "Matching: 72\n",
      "Matching: 73\n",
      "Matching: 85\n",
      "Matching: 91\n",
      "Matching: 92\n",
      "Matching: 97\n",
      "Matching: 98\n",
      "Matching: 104\n",
      "Matching: 105\n",
      "Matching: 106\n",
      "Matching: 107\n",
      "Matching: 108\n",
      "Matching: 109\n",
      "Matching: 110\n",
      "Matching: 111\n",
      "Matching: 112\n",
      "Matching: 113\n",
      "Matching: 114\n",
      "Matching: 117\n",
      "Matching: 118\n",
      "Matching: 122\n",
      "Matching: 124\n",
      "Matching: 128\n",
      "Matching: 129\n",
      "Matching: 143\n",
      "Matching: 144\n",
      "Matching: 145\n",
      "Matching: 146\n",
      "Matching: 147\n",
      "Matching: 148\n",
      "Matching: 152\n",
      "Matching: 157\n",
      "Matching: 159\n",
      "Matching: 160\n",
      "Matching: 161\n",
      "Matching: 162\n",
      "Matching: 163\n",
      "Matching: 166\n",
      "Matching: 167\n",
      "Matching: 168\n",
      "Matching: 170\n",
      "Matching: 171\n",
      "Matching: 172\n",
      "Matching: 195\n",
      "Matching: 200\n",
      "Matching: 204\n",
      "Matching: 205\n",
      "Matching: 206\n",
      "Matching: 210\n",
      "Matching: 232\n",
      "Matching: 233\n",
      "Matching: 234\n",
      "Matching: 247\n",
      "Matching: 258\n",
      "Matching: 266\n",
      "Matching: 269\n",
      "Matching: 273\n",
      "Matching: 274\n",
      "Matching: 275\n",
      "Matching: 276\n",
      "Matching: 277\n",
      "Matching: 278\n",
      "Matching: 279\n",
      "Matching: 282\n",
      "Matching: 287\n",
      "Matching: 296\n",
      "Matching: 302\n",
      "Matching: 305\n",
      "Matching: 324\n",
      "Matching: 330\n",
      "Matching: 334\n",
      "Matching: 335\n",
      "Matching: 336\n",
      "Matching: 337\n",
      "Matching: 352\n",
      "Matching: 353\n",
      "Matching: 354\n",
      "Matching: 355\n",
      "Matching: 356\n",
      "Matching: 364\n",
      "Matching: 367\n",
      "Matching: 368\n",
      "Matching: 370\n",
      "Matching: 394\n",
      "Matching: 400\n",
      "Matching: 402\n",
      "Matching: 403\n",
      "Matching: 406\n",
      "Matching: 432\n",
      "Matching: 433\n",
      "Matching: 449\n",
      "Matching: 450\n",
      "Matching: 472\n",
      "Matching: 476\n",
      "Matching: 477\n",
      "Matching: 478\n",
      "Matching: 485\n",
      "Matching: 486\n",
      "Matching: 487\n",
      "Matching: 488\n",
      "Matching: 489\n",
      "Matching: 493\n",
      "Matching: 502\n",
      "Matching: 516\n",
      "Matching: 535\n",
      "Matching: 536\n",
      "Matching: 537\n",
      "Matching: 544\n",
      "Matching: 550\n",
      "Matching: 551\n",
      "Matching: 565\n",
      "Matching: 566\n",
      "Matching: 567\n",
      "Matching: 568\n",
      "Matching: 569\n",
      "Matching: 587\n",
      "Matching: 590\n",
      "Matching: 604\n",
      "Matching: 605\n",
      "Matching: 607\n",
      "Matching: 610\n",
      "Matching: 611\n",
      "Matching: 612\n",
      "Matching: 615\n",
      "Matching: 618\n",
      "Matching: 629\n",
      "Matching: 644\n",
      "Matching: 645\n",
      "Matching: 659\n",
      "Matching: 666\n",
      "Matching: 669\n",
      "Matching: 673\n",
      "Matching: 674\n",
      "Matching: 711\n",
      "Matching: 719\n",
      "Matching: 720\n",
      "Matching: 721\n",
      "Matching: 724\n",
      "Matching: 727\n",
      "Matching: 732\n",
      "Matching: 733\n",
      "Matching: 734\n",
      "Matching: 735\n",
      "Matching: 761\n",
      "Matching: 762\n",
      "Matching: 764\n",
      "Matching: 767\n",
      "Matching: 772\n",
      "Matching: 773\n",
      "Matching: 776\n",
      "Matching: 779\n",
      "Matching: 782\n",
      "Matching: 793\n",
      "Matching: 796\n",
      "Matching: 797\n",
      "Matching: 801\n",
      "Matching: 803\n",
      "Matching: 804\n",
      "Matching: 807\n",
      "Matching: 822\n",
      "Matching: 827\n",
      "Matching: 828\n",
      "Matching: 829\n",
      "Matching: 830\n",
      "Matching: 834\n",
      "Matching: 841\n",
      "Matching: 843\n",
      "Matching: 844\n",
      "Matching: 849\n",
      "Matching: 857\n",
      "Matching: 859\n",
      "Matching: 861\n",
      "Matching: 864\n",
      "Matching: 866\n",
      "Matching: 872\n",
      "Matching: 873\n",
      "Matching: 875\n",
      "Matching: 877\n",
      "Matching: 878\n",
      "Matching: 914\n",
      "Matching: 915\n",
      "Matching: 916\n",
      "Matching: 917\n",
      "Matching: 918\n",
      "Matching: 926\n",
      "Matching: 927\n",
      "Matching: 928\n",
      "Matching: 929\n",
      "Matching: 934\n",
      "Matching: 935\n",
      "Matching: 946\n",
      "Matching: 947\n",
      "Matching: 953\n",
      "Matching: 956\n",
      "Matching: 957\n",
      "Matching: 960\n",
      "Matching: 961\n",
      "Matching: 977\n",
      "Matching: 978\n",
      "Matching: 981\n",
      "Matching: 985\n",
      "Matching: 986\n",
      "Matching: 988\n",
      "Matching: 992\n",
      "Matching: 1001\n",
      "Matching: 1008\n",
      "Matching: 1018\n",
      "Matching: 1020\n",
      "Matching: 1036\n",
      "Matching: 1053\n",
      "Matching: 1054\n",
      "Matching: 1055\n",
      "Matching: 1063\n",
      "Matching: 1064\n",
      "Matching: 1065\n",
      "Matching: 1066\n",
      "Matching: 1067\n",
      "Matching: 1068\n",
      "Matching: 1097\n",
      "Matching: 1101\n",
      "Matching: 1102\n",
      "Matching: 1103\n",
      "Matching: 1104\n",
      "Matching: 1119\n",
      "Matching: 1120\n",
      "Matching: 1122\n",
      "Matching: 1123\n",
      "Matching: 1128\n",
      "Matching: 1129\n",
      "Matching: 1130\n",
      "Matching: 1131\n",
      "Matching: 1138\n",
      "Matching: 1139\n",
      "Matching: 1149\n",
      "Matching: 1156\n",
      "Matching: 1161\n",
      "Matching: 1162\n",
      "Matching: 1182\n",
      "Matching: 1183\n",
      "Matching: 1184\n",
      "Matching: 1192\n",
      "Matching: 1195\n",
      "Matching: 1202\n",
      "Matching: 1203\n",
      "Matching: 1204\n",
      "Matching: 1205\n",
      "Matching: 1215\n",
      "Matching: 1225\n",
      "Matching: 1227\n",
      "Matching: 1241\n",
      "Matching: 1242\n",
      "Matching: 1243\n",
      "Matching: 1248\n",
      "Matching: 1252\n",
      "Matching: 1253\n",
      "Matching: 1256\n",
      "Matching: 1257\n",
      "Matching: 1258\n",
      "Matching: 1265\n",
      "Matching: 1266\n",
      "Matching: 1267\n",
      "Matching: 1268\n",
      "Matching: 1276\n",
      "Matching: 1277\n",
      "Matching: 1278\n",
      "Matching: 1279\n",
      "Matching: 1280\n",
      "Matching: 1281\n",
      "Matching: 1285\n",
      "Matching: 1287\n",
      "Matching: 1300\n",
      "Matching: 1311\n",
      "Matching: 1312\n",
      "Matching: 1317\n",
      "Matching: 1320\n",
      "Matching: 1327\n",
      "Matching: 1328\n",
      "Matching: 1341\n",
      "Matching: 1342\n",
      "Matching: 1343\n",
      "Matching: 1344\n",
      "Matching: 1345\n",
      "Matching: 1361\n",
      "Matching: 1362\n",
      "Matching: 1366\n",
      "Matching: 1377\n",
      "Matching: 1379\n",
      "Matching: 1402\n",
      "Matching: 1406\n",
      "Matching: 1407\n",
      "Matching: 1417\n",
      "Matching: 1418\n",
      "Matching: 1424\n",
      "Matching: 1425\n",
      "Matching: 1431\n",
      "Matching: 1432\n",
      "Matching: 1449\n",
      "Matching: 1454\n",
      "Matching: 1455\n",
      "Matching: 1456\n",
      "Matching: 1457\n",
      "Matching: 1458\n",
      "Matching: 1505\n",
      "Matching: 1506\n",
      "Matching: 1507\n",
      "Matching: 1508\n",
      "Matching: 1509\n",
      "Matching: 1510\n",
      "Matching: 1511\n",
      "Matching: 1512\n",
      "Matching: 1513\n",
      "Matching: 1514\n",
      "Matching: 1515\n",
      "Matching: 1516\n",
      "Matching: 1517\n",
      "Matching: 1518\n",
      "Matching: 1522\n",
      "Matching: 1524\n",
      "Matching: 1541\n",
      "Matching: 1568\n",
      "Matching: 1571\n",
      "Matching: 1572\n",
      "Matching: 1573\n",
      "Matching: 1621\n",
      "Matching: 1622\n",
      "Matching: 1623\n",
      "Matching: 1624\n",
      "Matching: 1625\n",
      "Matching: 1626\n",
      "Matching: 1627\n",
      "Matching: 1628\n",
      "Matching: 1630\n",
      "Matching: 1631\n",
      "Matching: 1632\n",
      "Matching: 1633\n",
      "Matching: 1634\n",
      "Matching: 1652\n",
      "Matching: 1655\n",
      "Matching: 1656\n",
      "Matching: 1661\n",
      "Matching: 1662\n",
      "Matching: 1664\n",
      "Matching: 1665\n",
      "Matching: 1693\n",
      "Matching: 1701\n",
      "Matching: 1702\n",
      "Matching: 1703\n",
      "Matching: 1713\n",
      "Matching: 1714\n",
      "Matching: 1715\n",
      "Matching: 1727\n",
      "Matching: 1745\n",
      "Matching: 1746\n",
      "Matching: 1748\n",
      "Matching: 1749\n",
      "Matching: 1751\n",
      "Matching: 1773\n",
      "Matching: 1789\n",
      "Matching: 1790\n",
      "Matching: 1797\n",
      "Matching: 1798\n",
      "Matching: 1810\n",
      "Matching: 1817\n",
      "Matching: 1818\n",
      "Matching: 1819\n",
      "Matching: 1831\n",
      "Matching: 1836\n",
      "Matching: 1845\n",
      "Matching: 1846\n",
      "Matching: 1847\n",
      "Matching: 1848\n",
      "Matching: 1850\n",
      "Matching: 1852\n",
      "Matching: 1854\n",
      "Matching: 1855\n",
      "Matching: 1856\n",
      "Matching: 1857\n",
      "Matching: 1858\n",
      "Matching: 1859\n",
      "Matching: 1860\n",
      "Matching: 1861\n",
      "Matching: 1875\n",
      "Matching: 1882\n",
      "Matching: 1892\n",
      "Matching: 1894\n",
      "Matching: 1895\n",
      "Matching: 1916\n",
      "Matching: 1923\n",
      "Matching: 1927\n",
      "Matching: 1928\n",
      "Matching: 1929\n",
      "Matching: 1930\n",
      "Matching: 1931\n",
      "Matching: 1932\n",
      "Matching: 1943\n",
      "Matching: 1966\n",
      "Matching: 1967\n",
      "Matching: 1994\n",
      "Matching: 2007\n",
      "Matching: 2011\n",
      "Matching: 2019\n",
      "Matching: 2020\n",
      "Matching: 2025\n",
      "Matching: 2026\n",
      "Matching: 2027\n",
      "Matching: 2028\n",
      "Matching: 2029\n",
      "Matching: 2030\n",
      "Matching: 2032\n",
      "Matching: 2033\n",
      "Matching: 2036\n",
      "Matching: 2038\n",
      "Matching: 2042\n",
      "Matching: 2043\n",
      "Matching: 2044\n",
      "Matching: 2048\n",
      "Matching: 2049\n",
      "Matching: 2050\n",
      "Matching: 2051\n",
      "Matching: 2052\n",
      "Matching: 2053\n",
      "Matching: 2062\n",
      "Matching: 2063\n",
      "Matching: 2114\n",
      "Matching: 2118\n",
      "Matching: 2119\n",
      "Matching: 2120\n",
      "Matching: 2121\n",
      "Matching: 2122\n",
      "Matching: 2123\n",
      "Matching: 2128\n",
      "Matching: 2135\n",
      "Matching: 2146\n",
      "Matching: 2147\n",
      "Matching: 2149\n",
      "Matching: 2150\n",
      "Matching: 2158\n",
      "Matching: 2175\n",
      "Matching: 2179\n",
      "Matching: 2197\n",
      "Matching: 2205\n",
      "Matching: 2209\n",
      "Matching: 2212\n",
      "Matching: 2213\n",
      "Matching: 2215\n",
      "Matching: 2219\n",
      "Matching: 2221\n",
      "Matching: 2234\n",
      "Matching: 2237\n",
      "Matching: 2242\n",
      "Matching: 2244\n",
      "Matching: 2256\n",
      "Matching: 2257\n",
      "Matching: 2258\n",
      "Matching: 2263\n",
      "Matching: 2284\n",
      "Matching: 2288\n",
      "Matching: 2305\n",
      "Matching: 2307\n",
      "Matching: 2308\n",
      "Matching: 2312\n",
      "Matching: 2313\n",
      "Matching: 2314\n",
      "Matching: 2315\n",
      "CPU times: total: 59min 32s\n",
      "Wall time: 18min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "matching = []\n",
    "not_matching = []\n",
    "the_predicted = []\n",
    "the_actual = []\n",
    "print(len(data_to_test))\n",
    "for idx in range(len(data_to_test)):\n",
    "    # if confidence < threshold:\n",
    "        # Get descriptions for both entities\n",
    "    item = data_to_test[idx]\n",
    "    head = item['head_side_information']\n",
    "    tail = item['tail_side_information']\n",
    "\n",
    "    unseen_relation = predict_unseen_relation(\n",
    "        head, tail, bert_model, tokenizer, unseen_relation_labels\n",
    "    )\n",
    "    \n",
    "    # print(f\"Unseen relation predicted for {head} -> {tail}: {unseen_relation[0]} with score {unseen_relation[1]}\")\n",
    "    if unseen_relation[0][0] == item['relation']:\n",
    "        print(f\"Matching: {idx}\")\n",
    "        matching.append({\"data\": item, \"unseen_relation_with_score\": unseen_relation})\n",
    "    else:\n",
    "        not_matching.append({\"data\": item, \"unseen_relation_with_score\": unseen_relation})\n",
    "    the_predicted.append(unseen_relation[0])\n",
    "    the_actual.append(item['relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b2305f-bf9b-4c4a-b8bd-018eeea6e0fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "617ca359-5bff-46db-b07d-39aa274a2057",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cb5c855-fa03-47e6-b67e-296fcadf9c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_relation_labels_to_int = {unseen_relation_labels[index]:index for index in range(len(unseen_relation_labels))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97a910cd-e16b-4b3e-b92c-4f480cc60d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_predicted_mapped_to_int = [unseen_relation_labels_to_int[item[0]] for item in the_predicted]\n",
    "the_actual_mapped_to_int = [unseen_relation_labels_to_int[item] for item in the_actual]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49e5963e-8abe-4fc7-b49f-3d6b87e58fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Unseen Relation Label Count: 4\n",
      "All Unseen Relation Label Count: 5\n",
      "All Unseen Relation Label: ['manufacturer', 'director', 'place of birth', 'member of', 'influenced by']\n",
      "Matched Unseen Relation Label: {'director', 'influenced by', 'member of', 'manufacturer'}\n",
      "All Unseen Relation Label with Count: Counter({'member of': 992, 'place of birth': 738, 'director': 382, 'manufacturer': 188, 'influenced by': 20})\n",
      "Predicted Unseen Relation Label with Count: Counter({'director': 2215, 'member of': 79, 'influenced by': 16, 'manufacturer': 10})\n",
      "Total Instance that Has Unseen Label 2320\n",
      "Total Instance that Matching 472\n",
      "macro_f1_score 0.3320907342660143\n",
      "micro_f1_score 0.20344827586206893\n",
      "weighted_f1_score 0.11922469427431073\n",
      "macro_precision 0.34612145326742294\n",
      "micro_precision 0.20344827586206896\n",
      "weighted_precision 0.5229349239787056\n",
      "macro_recall 0.3191532258064516\n",
      "micro_recall 0.20344827586206896\n",
      "weighted_recall 0.20344827586206896\n",
      "acc 0.20344827586206896\n"
     ]
    }
   ],
   "source": [
    "print(\"Matched Unseen Relation Label Count:\", len(set([item[0] for item in the_predicted])))\n",
    "print(\"All Unseen Relation Label Count:\",len(set(the_actual)))\n",
    "print(\"All Unseen Relation Label:\", unseen_relation_labels)\n",
    "print(\"Matched Unseen Relation Label:\", set([item[0] for item in the_predicted]))\n",
    "print(\"All Unseen Relation Label with Count:\", Counter(the_actual))\n",
    "print(\"Predicted Unseen Relation Label with Count:\", Counter([item[0] for item in the_predicted]))\n",
    "print(\"Total Instance that Has Unseen Label\", len(data_to_test))\n",
    "print(\"Total Instance that Matching\", len(matching))\n",
    "\n",
    "micro_precision,micro_recall,micro_f1_score = eval.compute_micro_PRF(np.asarray(the_predicted_mapped_to_int, dtype=np.float32), np.asarray(the_actual_mapped_to_int, dtype=np.float32))\n",
    "macro_precision,macro_recall,macro_f1_score = eval.compute_macro_PRF(np.asarray(the_predicted_mapped_to_int, dtype=np.float32), np.asarray(the_actual_mapped_to_int, dtype=np.float32))\n",
    "\n",
    "\n",
    "print(\"macro_f1_score\", macro_f1_score)\n",
    "print(\"micro_f1_score\", micro_f1_score)\n",
    "print(\"weighted_f1_score\", weighted_f1_score)\n",
    "print(\"macro_precision\", macro_precision)\n",
    "print(\"micro_precision\", micro_precision)\n",
    "print(\"weighted_precision\", weighted_precision)\n",
    "print(\"macro_recall\", macro_recall)\n",
    "print(\"micro_recall\", micro_recall)\n",
    "print(\"weighted_recall\", weighted_recall)\n",
    "print(\"acc\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7bddf9ff-6375-4615-acba-f0d5815ff654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "15\n",
      "['investor', 'ethnic group', 'league', 'mother', 'diplomatic relation', 'part of', 'organizer', 'operator', 'spouse', 'child', 'coach of sports team', 'product or material produced', 'founded by', 'manufacturer', 'sibling']\n",
      "{'coach of sports team', 'product or material produced', 'diplomatic relation', 'organizer'}\n",
      "Counter({'ethnic group': 19, 'organizer': 19, 'coach of sports team': 19, 'part of': 19, 'child': 19, 'manufacturer': 18, 'diplomatic relation': 17, 'spouse': 12, 'league': 12, 'mother': 11, 'founded by': 10, 'sibling': 9, 'product or material produced': 8, 'investor': 8, 'operator': 8})\n",
      "Counter({'coach of sports team': 154, 'product or material produced': 32, 'diplomatic relation': 21, 'organizer': 1})\n",
      "macro_f1_score 0.08394179089341852\n",
      "micro_f1_score 0.18269230769230768\n",
      "weighted_f1_score 0.09949261075097704\n",
      "macro_precision 0.12876082251082252\n",
      "micro_precision 0.18269230769230768\n",
      "weighted_precision 0.164601023976024\n",
      "macro_recall 0.15399896800825594\n",
      "micro_recall 0.18269230769230768\n",
      "weighted_recall 0.18269230769230768\n",
      "acc 0.18269230769230768\n"
     ]
    }
   ],
   "source": [
    "print(len(set(the_predicted)))\n",
    "print(len(set(the_actual)))\n",
    "print(unseen_relation_labels)\n",
    "print(set(the_predicted))\n",
    "print(Counter(the_actual))\n",
    "print(Counter(the_predicted))\n",
    "\n",
    "print(\"macro_f1_score\", macro_f1_score)\n",
    "print(\"micro_f1_score\", micro_f1_score)\n",
    "print(\"weighted_f1_score\", weighted_f1_score)\n",
    "print(\"macro_precision\", macro_precision)\n",
    "print(\"micro_precision\", micro_precision)\n",
    "print(\"weighted_precision\", weighted_precision)\n",
    "print(\"macro_recall\", macro_recall)\n",
    "print(\"micro_recall\", micro_recall)\n",
    "print(\"weighted_recall\", weighted_recall)\n",
    "print(\"acc\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "89cc3bad-2a26-478b-9716-ad0fc23890ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.00      0.00      0.00        19\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00        11\n",
      "           4       0.71      0.88      0.79        17\n",
      "           5       0.00      0.00      0.00        19\n",
      "           6       1.00      0.05      0.10        19\n",
      "           7       0.00      0.00      0.00         8\n",
      "           8       0.00      0.00      0.00        12\n",
      "           9       0.00      0.00      0.00        19\n",
      "          10       0.12      1.00      0.22        19\n",
      "          11       0.09      0.38      0.15         8\n",
      "          12       0.00      0.00      0.00        10\n",
      "          13       0.00      0.00      0.00        18\n",
      "          14       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.18       208\n",
      "   macro avg       0.13      0.15      0.08       208\n",
      "weighted avg       0.16      0.18      0.10       208\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcha0133\\Desktop\\Dynamic Relation Extraction (DRE)\\My Solution\\pykeen_only\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\mcha0133\\Desktop\\Dynamic Relation Extraction (DRE)\\My Solution\\pykeen_only\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\mcha0133\\Desktop\\Dynamic Relation Extraction (DRE)\\My Solution\\pykeen_only\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(the_actual_mapped_to_int, the_predicted_mapped_to_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2e4cad18-f4f8-4564-b7a8-fe38d1b7dff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.48285308441558444, 0.16499889429455994, 0.2459519385706299)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval.compute_macro_PRF(np.asarray(the_predicted_mapped_to_int, dtype=np.float32), np.asarray(the_actual_mapped_to_int, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9ffcc457-20bb-48c9-822f-171a9d0242f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.18269230769230768, 0.18269230769230768, 0.18269230769230765)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval.compute_micro_PRF(np.asarray(the_predicted_mapped_to_int, dtype=np.float32), np.asarray(the_actual_mapped_to_int, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddca051-b001-4fce-a9c8-0f2100769111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykeen_only",
   "language": "python",
   "name": "pykeen_only"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
